\section{Conclusion}
In this thesis we provided an implementation of a plan GAN and a Wasserstein GAN. Then we described  a method that can be used to compare these two networks. Although the proposed method requires some manual analysis we were able to come to a conclusion that the Wassersteing GAN does not improve the quality of produced image samples. However, as we showed, it has some advantages, like a loss function for the generator that corresponds to the quality of images produced by it. Also Wasserstein GANs less sensible to the choice of hyper-parameters than the plan GANs, which allows to reduce the time spent on finding the right setting. 

After applying the modified generative adversarial metric we could observe that the discriminator of a plan GAN overfits in a sense that it tries to remember who the images produced by its generator look like instead of trying to understand how the real faces should look like. We conducted more experiments to find an image that will be marked by the GAN discriminator as a real one by searching on the whole image space. It turned out that the GAN discriminator considers a random noise image as a real one, which suggests that its computed function is equal to one almost on the whole domain. Also, in another experiment we came to a conclusion that after adding a sufficient amount of noise to a generated image the discriminator start to mark it as a real one. All these results mean that the discriminator should be used only to train the generator network and is useless on its own.
 
During the writing of this paper a new, improved version of a Wasserstein GAN was published~\cite{improved_wgan}. In their work the authors tried another method to enforce the Lipschitz constraint of the discriminator. Instead of weight clipping they penalized the norm of the discriminator gradients. Moreover, a new GAN architecture was published in April 2017, which uses a variational auto-encoder as a discriminator~\citep{alexnet}. The authors were able to double the resolution of the generated images and used the Inception metric to show that their model performs better on the CIFAR-10 data set. It would be interesting to apply the metric proposed in this paper to try to analyze these two new GANs. 