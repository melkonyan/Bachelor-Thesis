While providing impressive results in such domains as image and music generation, generative adversarial networks have proven to be sensitive to the choice of hyper-parameters and hard to evaluate. First problem was tackled by the authors of the Wasserstein GAN, who introduced a new loss function based on the Earth Mover distance between the generated and the real data distributions. The evaluation problem remains an open issue. Several methods have been proposed to automatically evaluate performance of GANs, including the generative adversarial metric which allows to compare two GANs and tell which one produces better results. In this work I provide an implementation of the Wasserstein GAN and compare it to a plain GAN, which uses cross-entropy loss function, using a modified version of the generative adversarial metric. Furthermore, I provide some insights about the function learned by GAN discriminator by providing different images it considers to be real, but which do not look real for a human. 